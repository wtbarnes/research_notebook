{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import astropy.constants as const\n",
    "import astropy.units as u\n",
    "import astropy.table\n",
    "import ChiantiPy.tools.util as ch_util\n",
    "import ChiantiPy.tools.io as ch_io\n",
    "import ChiantiPy.core as ch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch_dbase = os.environ['XUVTOP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Raw CHIANTI Data\n",
    "In this notebook, we'll develop some tools for parsing the raw ASCII data in the CHIANTI atomic database and transforming it into pandas dataframes. It is important to include a way to very easily parse the actual raw data in the ChiantiPy package.\n",
    "\n",
    "Then, the next step is to transform these dataframes into one large HDF5 file. ChiantiPy will then use this file like a database to stream the needed atomic data from. This provides a sleeker interface to the data itself and can be much more efficient than the current system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Database Structure\n",
    "Other directories/files that are **not** ions:\n",
    "* __abundance__\n",
    "* ancillary_data\n",
    "* continuum\n",
    "* dem\n",
    "* __ioneq__\n",
    "* __ip__\n",
    "* masterlist\n",
    "* VERSION (file)\n",
    "\n",
    "The items in bold can be parsed appropriately and attached to the ion data objects.\n",
    "\n",
    "The filetypes for each ion are:\n",
    "* ~~**.elvlc**~~\n",
    "* ~~**.wgfa**~~\n",
    "* ~~.scups~~\n",
    "* .psplups\n",
    "* .rrparams\n",
    "* .trparams\n",
    "* .diparams\n",
    "* .drparams\n",
    "* ~~**.easplom**~~\n",
    "* ~~**.easplups**~~\n",
    "* ~~**.fblvl**~~\n",
    "* .cilvl\n",
    "* .reclvl\n",
    "\n",
    "The items in bold have a basic row-column structure and can be easily read using just a list of column names and datatypes.\n",
    "\n",
    "Those not bolded will be a bit more complicated.\n",
    "\n",
    "One possible idea would be to force everything into the basic row-column format. This could be done by providing preprocessors for specific filetypes and then a general filereader. This would help the code be less verbose and more maintable.\n",
    "\n",
    "For those entries which are arrays, the preprocesor could take those rows, turn them into comma separated lists, make them an item in the row (i.e. a single entry) and then give them a custom datatype that can later be used to just convert this into a Numpy array.\n",
    "\n",
    "Goal of the preprocessor should be to force every distinct entry into a single space-delimited row where each entry is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Parse Raw ASCII Data\n",
    "Each CHIANTI filetype seems to have a completely different layout. We do not want the user to have to worry about this. We've implemented a basic factory pattern that creates a different parser based on the input filetype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParserFactory(type):\n",
    "    def __call__(cls,*args,**kwargs):\n",
    "        filetype = args[0].split('.')[-1]\n",
    "        if filetype == 'elvlc':\n",
    "            return ElvlcParser(*args,**kwargs)\n",
    "        elif filetype == 'wgfa':\n",
    "            return WgfaParser(*args,**kwargs)\n",
    "        elif filetype == 'fblvl':\n",
    "            return FblvlParser(*args,**kwargs)\n",
    "        elif filetype == 'scups':\n",
    "            return ScupsParser(*args,**kwargs)\n",
    "        elif filetype == 'easplom':\n",
    "            return EasplomParser(*args,**kwargs)\n",
    "        elif filetype == 'easplups':\n",
    "            return EasplupsParser(*args,**kwargs)\n",
    "        elif filetype == 'psplups':\n",
    "            return PsplupsParser(*args,**kwargs)\n",
    "        else:\n",
    "            return type.__call__(cls,*args,**kwargs)\n",
    "\n",
    "        \n",
    "class GenericParser(object):\n",
    "    \n",
    "    def __init__(self,ion_filename):\n",
    "        self.ion_filename = ion_filename\n",
    "        self.filetype = self.ion_filename.split('.')[-1]\n",
    "        self.ion_name = self.ion_filename.split('.')[0]\n",
    "        self.element = self.ion_name.split('_')[0]\n",
    "        \n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        Generate Astropy QTable from a CHIANTI ion file \n",
    "        \"\"\"\n",
    "        with open(os.path.join(ch_dbase,self.element,self.ion_name,self.ion_filename),'r') as f:\n",
    "            lines = f.readlines()\n",
    "        table = []\n",
    "        for i,line in enumerate(lines):\n",
    "            line = list(filter(None,line.strip().split('  ')))\n",
    "            if line[0] == '-1':\n",
    "                comment = ''.join(lines[i+1:len(lines)])\n",
    "                break\n",
    "            else:\n",
    "                self.preprocessor(table,line,i)\n",
    "        \n",
    "        df = astropy.table.QTable(data=list(map(list,zip(*table))), names=self.headings)\n",
    "        for name,unit,dtype in zip(self.headings,self.units,self.dtypes):\n",
    "            df[name].unit = unit\n",
    "            df[name] = df[name].astype(dtype)\n",
    "        \n",
    "        df.meta['footer'] = comment\n",
    "        df.meta['element'] = self.element\n",
    "        df.meta['ion'] = self.ion_name\n",
    "        return df\n",
    "    \n",
    "    def preprocessor(self,table,line,index):\n",
    "        \"\"\"\n",
    "        Default preprocessor method\n",
    "        \"\"\"\n",
    "        table.append(line)\n",
    "        \n",
    "\n",
    "class Parser(GenericParser,metaclass=ParserFactory):\n",
    "    def __init__(self,ion_filename):\n",
    "        super().__init__(ion_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessors\n",
    "Preprocessors are essentially middleware that know the details of the specific filetype we're parsing. This makes it so that there is one common interface to parsing all files and the middleware is selected based on the supplied extension. These are instantiated by the factory and should not be instantiated manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ElvlcParser(GenericParser):\n",
    "    dtypes = [int,str,int,str,float,float,float]\n",
    "    units = [None,None,None,None,u.dimensionless_unscaled,1/u.cm,1/u.cm]\n",
    "    headings = ['level index','configuration','multiplicity',\n",
    "                'orbital angular momentum','total angular momentum',\n",
    "                'observed energy','theoretical energy']\n",
    "\n",
    "    \n",
    "class FblvlParser(GenericParser):\n",
    "    dtypes = [int,str,int,int,str,int,float,float]\n",
    "    units = [None,None,None,None,None,None,1/u.cm,1/u.cm]\n",
    "    headings = ['level index','configuration','principal quantum number',\n",
    "                'azimuthal quantum number','orbital angular momentum',\n",
    "                'multiplicity','observed energy','theoretical energy']\n",
    "\n",
    "    \n",
    "class ScupsParser(GenericParser): \n",
    "    \n",
    "    dtypes = [int,int,float,float,float,int,int,float,'object','object']\n",
    "    units = [None,None,u.Ry,u.dimensionless_unscaled,1/u.Ry,None,None,\n",
    "             u.dimensionless_unscaled,u.dimensionless_unscaled,\n",
    "             u.dimensionless_unscaled]\n",
    "    headings = ['lower level index','upper level index','delta energy','oscillator strength',\n",
    "                'high-temperature limit','number of scaled temperatures','Burgess-Tully scaling type',\n",
    "                'Burgess-Tully scaling parameter','Burgess-Tully scaled temperatures',\n",
    "                'Burgess-Tully scaled effective collision strengths']\n",
    "    \n",
    "    def preprocessor(self,table,line,index):\n",
    "        if index%3 == 0:\n",
    "            # main data\n",
    "            table.append(line)\n",
    "        else:\n",
    "            # scaled temperature or collision strengths\n",
    "            scaled = np.array(line,dtype=float)\n",
    "            table[-1].append(scaled)\n",
    "            \n",
    "class PsplupsParser(GenericParser):\n",
    "    \n",
    "    dtypes = [int,int,int,float,float,float,float]\n",
    "    units = [None,None,None,u.dimensionless_unscaled,u.Ry,u.dimensionless_unscaled,\n",
    "             u.dimensionless_unscaled]\n",
    "    headings = ['lower level index','upper level index','Burgess-Tully scaling type',\n",
    "                'oscillator strength','delta energy','Burgess-Tully scaling parameter',\n",
    "                'Burgess-Tully scaled effective collision strengths']\n",
    "    \n",
    "    def preprocessor(self,table,line,index):\n",
    "        line = list(filter(None,('      '.join(line)).split()))\n",
    "        row = line[:5]\n",
    "        tmp = line[5]\n",
    "        i_split = [i for i,char in enumerate(tmp) if char=='-' and tmp[i-1]!='e'][0]\n",
    "        row += [tmp[:i_split]]\n",
    "        scups = [tmp[i_split+1:]] \n",
    "        tmp_scups = line[6:]\n",
    "        if len(tmp_scups[-1].split('-')) > 2:\n",
    "            tmp = tmp_scups[-1]\n",
    "            i_split = [i for i,char in enumerate(tmp) if char=='-' and tmp[i-1]!='e'][0]\n",
    "            tmp_scups = tmp_scups[:-1] + [tmp[:i_split],tmp[i_split+1:]]\n",
    "        scups = np.array(scups+tmp_scups,dtype=float)\n",
    "        row += [scups]\n",
    "        table.append(row)\n",
    "        \n",
    "            \n",
    "class EasplomParser(GenericParser):\n",
    "    \n",
    "    dtypes = [int,int,int,float,float,float,float]\n",
    "    units = [None,None,None,u.dimensionless_unscaled,u.Ry,u.dimensionless_unscaled,\n",
    "             u.dimensionless_unscaled]\n",
    "    headings = ['lower level index','upper level index','Burgess-Tully scaling type',\n",
    "                'oscillator strength','delta energy','Burgess-Tully scaling parameter',\n",
    "                'Burgess-Tully scaled cross-section']\n",
    "    \n",
    "    def preprocessor(self,table,line,index):\n",
    "        line = list(filter(None,('      '.join(line)).split()))\n",
    "        scaled_cs = np.array(line[8:],dtype=float)\n",
    "        row = line[2:8] + [scaled_cs]\n",
    "        table.append(row)\n",
    "        \n",
    "        \n",
    "class EasplupsParser(EasplomParser):\n",
    "    dtypes = [int,int,int,float,float,float,float]\n",
    "    units = [None,None,None,u.dimensionless_unscaled,u.Ry,u.dimensionless_unscaled,\n",
    "             u.dimensionless_unscaled]\n",
    "    headings = ['lower level index','upper level index','Burgess-Tully scaling type',\n",
    "                'oscillator strength','delta energy','upsilon coefficient',\n",
    "                'excitation-autoionization rate coefficients']\n",
    "    \n",
    "    \n",
    "class WgfaParser(GenericParser):\n",
    "    \n",
    "    dtypes = [np.int,np.int,np.float,np.float,np.float,\n",
    "              str,np.int,str,np.float,\n",
    "              str,np.int,str,np.float]\n",
    "    units = [None,None,u.angstrom,u.dimensionless_unscaled,1/u.s,None,None,None,None,\n",
    "             None,None,None,None]\n",
    "    headings = ['lower level index','upper level index',\n",
    "                'transition wavelength','oscillator strength','radiative decay rate',\n",
    "                'lower level configuration','lower level multiplicity',\n",
    "                'lower level orbital angular momentum',\n",
    "                'lower level total angular momentum',\n",
    "                'upper level configuration','upper level multiplicity',\n",
    "                'upper level orbital angular momentum',\n",
    "                'upper level total angular momentum']\n",
    "    \n",
    "    def preprocessor(self,table,line,index):\n",
    "        ### lower ###\n",
    "        tmp = line[-2].strip().split()\n",
    "        del tmp[-1] # delete rogue dash\n",
    "        tmp_pretty = tmp[-1]\n",
    "        config = ' '.join(tmp[:-1])\n",
    "        mult = tmp_pretty[0]\n",
    "        orb = tmp_pretty[1]\n",
    "        frac = tmp_pretty[2:]\n",
    "        if len(frac) == 1:\n",
    "            frac = frac[0]\n",
    "        else:\n",
    "            frac = float(frac.split('/')[0])/float(frac.split('/')[-1])\n",
    "        lower = [config,mult,orb,frac] \n",
    "        ### upper ###\n",
    "        tmp = line[-1].strip().split()\n",
    "        tmp_pretty = tmp[-1]\n",
    "        config = ' '.join(tmp[:-1])\n",
    "        mult = tmp_pretty[0]\n",
    "        orb = tmp_pretty[1]\n",
    "        frac = tmp_pretty[2:]\n",
    "        if len(frac) == 1:\n",
    "            frac = frac[0]\n",
    "        else:\n",
    "            frac = float(frac.split('/')[0])/float(frac.split('/')[-1])\n",
    "        upper = [config,mult,orb,frac] \n",
    "        ### recombine and assemble ###\n",
    "        table.append(line[:-2] + lower + upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying it out\n",
    "Parse some example files for all of the filetypes using our parser factory approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `.scups` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parser('fe_6.scups').parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `.psplups` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parser('ca_17.psplups').parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.elvlc` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parser('h_1.elvlc').parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `.easplom` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parser('fe_6.easplom').parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `.easplups` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parser('fe_6.easplups').parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.fblvl` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parser('ar_16.fblvl').parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.wgfa` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parser('he_2.wgfa').parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check Raw Text\n",
    "Call tail on the actual file to make sure we are parsing the right stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 10 $XUVTOP/fe/fe_6/fe_6.scups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 10 $XUVTOP/ca/ca_17/ca_17.psplups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 10 $XUVTOP/h/h_1/h_1.elvlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 100 $XUVTOP/fe/fe_6/fe_6.easplom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 10 $XUVTOP/fe/fe_6/fe_6.easplups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 30 $XUVTOP/h/h_1/h_1.fblvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 100 $XUVTOP/fe/fe_3/fe_3.wgfa"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:chiantipy]",
   "language": "python",
   "name": "conda-env-chiantipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
