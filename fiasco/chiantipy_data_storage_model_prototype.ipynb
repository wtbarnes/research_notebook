{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototyping a Data Storage Model for ChiantiPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import astropy.units as u\n",
    "#import ChiantiPy.tools.util as ch_util\n",
    "#import ChiantiPy.tools.io as ch_io\n",
    "#import ChiantiPy.core as ch\n",
    "import fiasco\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Access Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHIANTI has several file formats that it stores for each ion. The most notable are,\n",
    "\n",
    "* `.elvlc`: energy levels (in cm$^{-1}$) with additional level configuration\n",
    "* `.wgfa`: wavelengths, oscillator strengths, and Einstein A coefficients for the transitions\n",
    "* `.scups`: temperatures and effective collision strenghts for each transition. Replaces the old `.splups` files. There are also still `.psplups` files\n",
    "* Additional files:\n",
    "  * `.fblvl`: information for calculating free-bound continuum\n",
    "  * `.cilvl`, `.reclvl`: ionization and recombination rates\n",
    "\n",
    "Essentially, we want to have a property for each of these files. Each of these properties returns an object with a `__getitem__` method that takes in the keys associated with each of these files. These objects return the relevant data streamed out of the HDF5 file.\n",
    "\n",
    "Ideally, this file would be built once the first time you download ChiantiPy and then only rebuilt when your installed CHIANTI database gets updated. The filename is then stored at the package level. We'll use our CHIANTI database HDF5 file that we've been using in `synthesizAR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chianti_hdf5_filename = '/Users/willbarnes/.fiasco/chianti_dbase.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataIndexer(object):\n",
    "    \n",
    "    def __init__(self,top_level_path):\n",
    "        self.top_level_path = top_level_path\n",
    "    \n",
    "    def __getitem__(self,key):\n",
    "        with h5py.File(chianti_hdf5_filename,'r') as hf:\n",
    "            grp = hf[self.top_level_path]\n",
    "            if key not in grp:\n",
    "                raise IndexError('{} not a valid dataset for {}'.format(key,self.top_level_path))\n",
    "            ds = grp[key]\n",
    "            if ds.attrs['unit'] is 'SKIP':\n",
    "                data = np.array(ds)\n",
    "            else:\n",
    "                data = u.Quantity(ds,ds.attrs['unit'])\n",
    "        return data\n",
    "    \n",
    "    def __repr__(self):\n",
    "        with h5py.File(chianti_hdf5_filename,'r') as hf:\n",
    "            grp = hf[self.top_level_path]\n",
    "            var_names = [(key,grp[key].dtype.str,grp[key].attrs['unit']) \n",
    "                         if grp[key].attrs['unit']!='SKIP' else (key,'') for key in grp]\n",
    "            footer = grp.attrs['footer']\n",
    "            \n",
    "        name_strs = '\\n'.join(['{} ({}) -- {}'.format(v[0],v[1],v[2]) for v in var_names])\n",
    "        return '''{top_level_path}\n",
    "        \n",
    "Fields\n",
    "------\n",
    "{vars_and_units}\n",
    "\n",
    "Footer\n",
    "------\n",
    "{footer}\n",
    "        '''.format(top_level_path=self.top_level_path,vars_and_units=name_strs,footer=footer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GenericChiantiData(object):\n",
    "    \n",
    "    def __init__(self,ion_name):\n",
    "        self.ion_name = ion_name\n",
    "        self.element = ion_name.split('_')[0]\n",
    "        #self.Z = ch_util.el2z(self.element)\n",
    "        self.stage = ion_name.split('_')[-1]\n",
    "        \n",
    "    @property\n",
    "    def elvlc(self):\n",
    "        return DataIndexer('/'.join([self.element,self.ion_name,'elvlc']))\n",
    "    \n",
    "    @property\n",
    "    def wgfa(self):\n",
    "        return DataIndexer('/'.join([self.element,self.ion_name,'wgfa']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = GenericChiantiData('h_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$[0,~82258.956,~82258.921,~82259.287,~97492.224,~97492.213,~97492.321,~97492.321,~97492.357,~102823.85,~102823.85,~102823.9,~102823.9,~102823.91,~102823.91,~102823.92,~105291.63,~105291.63,~105291.65,~105291.65,~105291.66,~105291.66,~105291.67,~105291.67,~105291.67] \\; \\mathrm{\\frac{1}{cm}}$"
      ],
      "text/plain": [
       "<Quantity [      0.   ,  82258.956,  82258.921,  82259.287,  97492.224,\n",
       "             97492.213,  97492.321,  97492.321,  97492.357, 102823.855,\n",
       "            102823.851, 102823.896, 102823.896, 102823.911, 102823.911,\n",
       "            102823.919, 105291.633, 105291.631, 105291.654, 105291.654,\n",
       "            105291.662, 105291.662, 105291.666, 105291.666, 105291.668] 1 / cm>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.elvlc['observed energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h/h_1/elvlc\n",
       "        \n",
       "Fields\n",
       "------\n",
       "configuration (|S2) -- \n",
       "level index (<i8) -- \n",
       "level label (|S1) -- \n",
       "multiplicity (<i8) -- \n",
       "observed energy (<f8) -- 1 / cm\n",
       "orbital angular momentum (|S1) -- \n",
       "theoretical energy (<f8) -- 1 / cm\n",
       "total angular momentum (<f8) -- \n",
       "\n",
       "Footer\n",
       "------\n",
       "%filename: h_1.elvlc\n",
       "%observed energy levels: Fuhr et al, 1999, NIST Atomic Spectra Database Version 2.0\n",
       "%produced as part of the Arcetri/Cambridge/NRL 'CHIANTI' atomic data base collaboration\n",
       "%\n",
       "%  Ken Dere  May 3 2001\n",
       "\n",
       "        "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.elvlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<i8\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(chianti_hdf5_filename,'r') as hf:\n",
    "    grp = hf['/h/h_1/elvlc']\n",
    "    var_names = [(key,grp[key].attrs['unit']) if grp[key].attrs['unit']!='SKIP' else (key,'') for key in grp]\n",
    "    print(grp['level index'].dtype.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('configuration', ''),\n",
       " ('level index', ''),\n",
       " ('level label', ''),\n",
       " ('multiplicity', ''),\n",
       " ('observed energy', '1 / cm'),\n",
       " ('orbital angular momentum', ''),\n",
       " ('theoretical energy', '1 / cm'),\n",
       " ('total angular momentum', '')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is specifically for an ion. We could also implement an even more generic class for the other non-ion-specific datasets, e.g. abundance, ionization potential, miscellaneous continuum data. \n",
    "\n",
    "Alternatively, when the CHIANTI HDF5 database is created, these could just be broken up by ion appropriately. This would work except for the continuum data which is maybe a special case anyway. \n",
    "\n",
    "Basically, we just want to avoid having to index things over and over again. Better to just refer to it by the ion name.\n",
    "\n",
    "Since this kind of data is used in quite a few places, we could provide it as a generic object. This also makes the CHIANTI data easily accessible without the baggage of the ion object if users want to extend it in anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print('{} -- {}'.format('\\n'.join(['1','2','4'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:fiasco]",
   "language": "python",
   "name": "conda-env-fiasco-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
